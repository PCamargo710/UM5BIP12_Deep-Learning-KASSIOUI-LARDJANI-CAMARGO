{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369ff5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "print(f\"Reproductibilité activée: seed={seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c649a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers, models\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers,models,callbacks\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Normalizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import davies_bouldin_score,calinski_harabasz_score, silhouette_score\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.manifold import TSNE\n",
    "from umap import UMAP\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import f_oneway\n",
    "import time\n",
    "from io import StringIO\n",
    "from joblib import Parallel, delayed\n",
    "import pickle\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(os.path.expanduser(\"~/projets/pro/BIP12: Artificial Intelligence\"))    #Change as needed\n",
    "print(f\"Working Directory:\\n{os.getcwd()}\\n\")\n",
    "print(f\"Keras version= {keras.__version__}\")\n",
    "print(f\"Pandas version= {pd.__version__}\")\n",
    "\n",
    "#Ensure reproductibility\n",
    "tf.config.experimental.enable_op_determinism()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f46125",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"data/mmc2.xlsx\", header=1)\n",
    "df = df.dropna(axis=0, how='all')\n",
    "df.columns = df.iloc[0]\n",
    "df = df.iloc[1:].reset_index(drop=True)\n",
    "df = df.rename(columns={\"Case.ID\": \"Case_ID\"})\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d832b4f1",
   "metadata": {},
   "source": [
    "## Téléchargement des données RNAseq à partir des CASE ID de chaque patient dans la liste cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c363e0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_tcga_rnaseq(case_id):\n",
    "    \"\"\"Télécharge les données RNAseq pour un case_id TCGA\"\"\"\n",
    "    url = \"https://api.gdc.cancer.gov/files\"\n",
    "    \n",
    "    filters = {\n",
    "        \"op\": \"and\",\n",
    "        \"content\": [\n",
    "            {\"op\": \"in\", \"content\": {\"field\": \"cases.submitter_id\", \"value\": [case_id]}},\n",
    "            {\"op\": \"in\", \"content\": {\"field\": \"files.data_type\", \"value\": [\"Gene Expression Quantification\"]}},\n",
    "            {\"op\": \"in\", \"content\": {\"field\": \"files.analysis.workflow_type\", \"value\": [\"STAR - Counts\"]}}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    params = {\n",
    "        \"filters\": json.dumps(filters),\n",
    "        \"fields\": \"file_id,file_name,cases.submitter_id\",\n",
    "        \"format\": \"JSON\",\n",
    "        \"size\": \"100\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "# Tester avec un patient\n",
    "test_case = df[\"Case_ID\"].iloc[0]\n",
    "result = download_tcga_rnaseq(test_case)\n",
    "print(f\"Fichiers trouvés pour {test_case}: {result['data']['pagination']['total']}\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8408bdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Fonction pour télécharger les données d'un fichier\n",
    "def download_gene_counts(file_id):\n",
    "    \"\"\"Télécharge le fichier de counts depuis GDC\"\"\"\n",
    "    url = f\"https://api.gdc.cancer.gov/data/{file_id}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # Lire le TSV\n",
    "        data = pd.read_csv(StringIO(response.text), sep='\\t', comment='#')\n",
    "        return data\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# 2. Construire la matrice pour tous les patients\n",
    "def build_expression_matrix(case_ids, max_patients=None):\n",
    "    \"\"\"\n",
    "    Construit la matrice d'expression pour une liste de patients\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    case_ids : list\n",
    "        Liste des Case_ID TCGA\n",
    "    max_patients : int, optional\n",
    "        Limite le nombre de patients (pour tester)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : Matrice patients × gènes\n",
    "    \"\"\"\n",
    "    \n",
    "    expression_data = {}\n",
    "    failed_cases = []\n",
    "    \n",
    "    # Limiter si spécifié\n",
    "    if max_patients:\n",
    "        case_ids = case_ids[:max_patients]\n",
    "    \n",
    "    print(f\"Téléchargement des données pour {len(case_ids)} patients...\")\n",
    "    \n",
    "    for i, case_id in enumerate(case_ids):\n",
    "        try:\n",
    "            # Récupérer le file_id\n",
    "            result = download_tcga_rnaseq(case_id)\n",
    "            \n",
    "            if result['data']['pagination']['total'] > 0:\n",
    "                file_id = result['data']['hits'][0]['file_id']\n",
    "                \n",
    "                # Télécharger les counts\n",
    "                counts = download_gene_counts(file_id)\n",
    "                \n",
    "                if counts is not None:\n",
    "                    # Extraire les counts (colonne 'unstranded' ou 'tpm_unstranded')\n",
    "                    # Adapter selon le format de vos fichiers\n",
    "                    gene_counts = counts.set_index('gene_name')['unstranded']\n",
    "                    expression_data[case_id] = gene_counts\n",
    "                    \n",
    "                    if (i + 1) % 10 == 0:\n",
    "                        print(f\"Téléchargé: {i + 1}/{len(case_ids)}\")\n",
    "                else:\n",
    "                    failed_cases.append(case_id)\n",
    "            else:\n",
    "                print(f\"Pas de fichier pour {case_id}\")\n",
    "                failed_cases.append(case_id)\n",
    "            \n",
    "            # Respecter les limites de l'API\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erreur pour {case_id}: {e}\")\n",
    "            failed_cases.append(case_id)\n",
    "    \n",
    "    # Créer le DataFrame (patients en lignes, gènes en colonnes)\n",
    "    expression_matrix = pd.DataFrame(expression_data).T\n",
    "    \n",
    "    print(f\"\\nMatrice construite: {expression_matrix.shape}\")\n",
    "    print(f\"  - Patients: {expression_matrix.shape[0]}\")\n",
    "    print(f\"  - Gènes: {expression_matrix.shape[1]}\")\n",
    "    if failed_cases:\n",
    "        print(f\"  - Échecs: {len(failed_cases)} patients\")\n",
    "    \n",
    "    return expression_matrix, failed_cases\n",
    "\n",
    "\"\"\"-------------------------------------------------------------\"\"\"\n",
    "\n",
    "# 3. TESTER avec quelques patients d'abord\n",
    "patients_with_rna = df[df['mRNA'].notna()]['Case_ID'].tolist()\n",
    "print(f\"Total patients avec mRNA: {len(patients_with_rna)}\")\n",
    "\n",
    "# TEST avec 5 patients\n",
    "test_matrix, failed = build_expression_matrix(patients_with_rna, max_patients=817)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a24f6dd",
   "metadata": {},
   "source": [
    "### Saving the resulting dataframe for future use without redownloading each time..then loading again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7efeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_cols = [c for c in test_matrix.columns if pd.isna(c)]\n",
    "print(f\"{len(nan_cols)} colonnes NaN supprimées\")\n",
    "test_matrix = test_matrix.drop(columns=nan_cols)\n",
    "test_matrix.to_pickle(\"dataframe.pkl\")\n",
    "df.to_pickle(\"data_cohort.pkl\")\n",
    "#test_matrix.head()\n",
    "#data_cohort.head()\n",
    "print(\"\\nDonnées sauvegardées\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa07ec1b",
   "metadata": {},
   "source": [
    "### Loading the pickled results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a021dd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matrix=pd.read_pickle(\"dataframe.pkl\")\n",
    "data_cohort=pd.read_pickle(\"data_cohort.pkl\")\n",
    "print(f\"Données chargées: {test_matrix.shape}\")\n",
    "print(f\"Méta données chargées: {data_cohort.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bd5906",
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = test_matrix.copy()\n",
    "lib_size = expr.sum(axis=1)\n",
    "cpm = (expr.T / lib_size).T * 1e6\n",
    "\n",
    "#Filters\n",
    "min_cpm = 1.0          # keep genes with CPM >= 1\n",
    "min_prop = 0.20        # ...in at least 20% of samples\n",
    "min_samples = int(np.ceil(min_prop * cpm.shape[0]))\n",
    "keep = (cpm >= min_cpm).sum(axis=0) >= min_samples\n",
    "cpm_filt = cpm.loc[:, keep]\n",
    "\n",
    "print(f\"Gènes gardés après le filtre d'expression: {cpm_filt.shape[1]} gènes\")\n",
    "log_cpm = np.log1p(cpm_filt)\n",
    "\n",
    "\n",
    "# 4) HVG by variance (top-K)\n",
    "top_k = 5000  \n",
    "gene_var = log_cpm.var(axis=0)\n",
    "hvg_genes = gene_var.sort_values(ascending=False).head(min(top_k, log_cpm.shape[1])).index\n",
    "\n",
    "expr_hvg = log_cpm[hvg_genes].copy()\n",
    "print(f\"Gènes gardés après le filtre de variance HVG: {expr_hvg.shape[1]} gènes\")\n",
    "print(f\"HVG matrix résultante: {expr_hvg.shape}\")\n",
    "\n",
    "# 5) Use HVGs downstream\n",
    "test_matrix_hvg = expr_hvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5082f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier d'abord les vrais noms des colonnes dans df\n",
    "print(df.columns)\n",
    "metadata_cols = [\"TumorPurity\", \"Final Pathology\", \"ProliferationScore\",'PAM50']\n",
    "\n",
    "# Créer une dataframe avec les métadonnées, indexée par Case_ID\n",
    "metadata = df[df['Case_ID'].isin(test_matrix.index)][['Case_ID'] + metadata_cols].set_index('Case_ID')\n",
    "\n",
    "# Ajouter les métadonnées à test_matrix\n",
    "test_matrix_with_meta = test_matrix_hvg.copy()\n",
    "test_matrix_with_meta = test_matrix_with_meta.join(metadata, how='left')\n",
    "\n",
    "print(f\"\\nColonnes des méta données à ajouter:\\n{metadata_cols}\")\n",
    "print(f\"\\nShape avant l'ajout des méta données: {test_matrix_hvg.shape}\")\n",
    "print(f\"Shape après l'ajout des méta données: {test_matrix_with_meta.shape}\\n\")\n",
    "#print(test_matrix_with_meta.iloc[:, -5:].head())\n",
    "#print(test_matrix_with_meta.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1949339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matrix_clean=test_matrix_hvg.copy()\n",
    "test_matrix_clean = test_matrix_clean.rename(columns={\"gene_name\": \"Case_ID\"})\n",
    "test_matrix_clean.shape\n",
    "#print(test_matrix_clean.iloc[:,-3:].head())\n",
    "test_matrix_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6690d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(whiten=True,random_state=seed)\n",
    "X_pca=pca.fit_transform(test_matrix_clean)\n",
    "print(\"\\n Data après PCA\")\n",
    "print(X_pca.shape)\n",
    "cumsum_var = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "# Trouver le nombre de composants pour 85%\n",
    "n_components_85 = np.argmax(cumsum_var >= 0.85) + 1\n",
    "\n",
    "print(f\"Nombre de PCs pour 85% variance: {n_components_85}\")\n",
    "print(f\"Variance expliquée: {cumsum_var[n_components_85-1]:.4f}\")\n",
    "\n",
    "# Visualiser\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(cumsum_var, linewidth=2, color=\"teal\")\n",
    "plt.axhline(y=0.85, color='r', linestyle='--', label='85%')\n",
    "plt.axvline(x=n_components_85, color='b', linestyle='--', label=f'n={n_components_85}')\n",
    "plt.title(\"Variance en fonction du nombre de PCs\")\n",
    "plt.xlabel(\"Nombre de PCs\")\n",
    "plt.ylabel(\"Variance cumulée\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc3e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_components_85)\n",
    "\n",
    "pca_reduced=PCA(n_components=n_components_85,random_state=seed)\n",
    "data_pca_reduced = pca_reduced.fit_transform(data_scaled)\n",
    "\n",
    "\n",
    "print(f\"Après PCA: {data_pca_reduced.shape}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
